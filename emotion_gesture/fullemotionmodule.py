import tkinter as tk
from tkinter import ttk, messagebox
import cv2
import numpy as np
from PIL import Image, ImageTk
import threading
import time
import webbrowser
import subprocess
import os
import platform
import warnings
import pyautogui
from queue import Queue
warnings.filterwarnings('ignore')

# --- Model / features (your pipeline) ---
import joblib
import mediapipe as mp
mp_face_mesh = mp.solutions.face_mesh
mp_hands = mp.solutions.hands
from collections import deque
from live_emotion_inference import FEATURE_ORDER, compute_features

MODEL_DIR = os.path.join(os.path.dirname(__file__), "model2")
MODEL_PATH = os.path.join(MODEL_DIR, "emotion_model.joblib")
LABELS_PATH = os.path.join(MODEL_DIR, "label_encoder.joblib")


# ==============================
# Hand Gesture Mouse Controller
# ==============================
class HandGestureController:
    def __init__(self):
        self.running = False
        self.is_active = False
        self.thread = None
        
        # Screen dimensions
        self.screen_width, self.screen_height = pyautogui.size()
        self.mid_screen_y = self.screen_height // 2
        
        # Smoothing
        self.smooth_factor = 0.5
        self.prev_mouse_x, self.prev_mouse_y = 0, 0
        
        # States
        self.last_toggle_time = 0
        
        # Left click/drag
        self.left_gesture_start = None
        self.dragging = False
        self.CLICK_HOLD_TIME = 0.5
        
        # Right click
        self.right_click_start = None
        self.right_click_active = False
        self.last_right_click_time = 0
        self.RIGHT_CLICK_HOLD = 0.3
        self.RIGHT_CLICK_COOLDOWN = 1.0
        
        # Vertical scroll
        self.SCROLL_INTERVAL = 0.15
        self.V_DEADZONE = max(30, int(self.screen_height * 0.05))
        self.last_scroll_time = 0.0
        
        # MediaPipe hands
        self.mp_hands = mp_hands
        self.hands = None
        
    def landmarks_to_array(self, lm_list):
        return np.array([[lm.x, lm.y, lm.z] for lm in lm_list])
    
    def finger_extended_np(self, lms, tip_idx, pip_idx):
        return lms[tip_idx, 1] < lms[pip_idx, 1]
    
    def thumb_really_extended_np(self, lms):
        tip = lms[self.mp_hands.HandLandmark.THUMB_TIP.value]
        ip = lms[self.mp_hands.HandLandmark.THUMB_IP.value]
        index_tip = lms[self.mp_hands.HandLandmark.INDEX_FINGER_TIP.value]
        return tip[0] < ip[0] and abs(tip[0] - index_tip[0]) > 0.08
    
    def five_fingers_extended(self, lms):
        tips = [8, 12, 16, 20]
        pips = [6, 10, 14, 18]
        return all(self.finger_extended_np(lms, t, p) for t, p in zip(tips, pips)) and self.thumb_really_extended_np(lms)
    
    def start(self, cap):
        if not self.running:
            self.running = True
            self.cap = cap
            self.thread = threading.Thread(target=self._run_gesture_control, daemon=True)
            self.thread.start()
            print("Hand Gesture Controller started")
    
    def stop(self):
        self.running = False
        self.is_active = False
        if self.hands:
            self.hands.close()
            self.hands = None
        print("Hand Gesture Controller stopped")
    
    def _run_gesture_control(self):
        self.hands = self.mp_hands.Hands(
            model_complexity=1,
            min_detection_confidence=0.6,
            min_tracking_confidence=0.6,
            max_num_hands=1
        )
        
        while self.running:
            if self.cap is None:
                time.sleep(0.1)
                continue
                
            ret, frame = self.cap.read()
            if not ret:
                time.sleep(0.03)
                continue
            
            frame = cv2.flip(frame, 1)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_frame)
            
            now = time.time()
            
            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]
                lms = self.landmarks_to_array(hand_landmarks.landmark)
                
                # Toggle activation with 5 fingers
                if self.five_fingers_extended(lms) and (now - self.last_toggle_time > 1.5):
                    self.is_active = not self.is_active
                    print("Virtual Mouse " + ("Activated" if self.is_active else "Deactivated"))
                    self.last_toggle_time = now
                
                if self.is_active:
                    # Finger states
                    index_ext = self.finger_extended_np(lms, 8, 6)
                    middle_ext = self.finger_extended_np(lms, 12, 10)
                    ring_ext = self.finger_extended_np(lms, 16, 14)
                    pinky_ext = self.finger_extended_np(lms, 20, 18)
                    thumb_ext = self.thumb_really_extended_np(lms)
                    
                    # Cursor movement
                    index_tip = lms[self.mp_hands.HandLandmark.INDEX_FINGER_TIP.value]
                    target_x = int(index_tip[0] * self.screen_width)
                    target_y = int(index_tip[1] * self.screen_height)
                    
                    if index_ext:
                        mouse_x = int(self.prev_mouse_x + (target_x - self.prev_mouse_x) * self.smooth_factor)
                        mouse_y = int(self.prev_mouse_y + (target_y - self.prev_mouse_y) * self.smooth_factor)
                        if abs(mouse_x - self.prev_mouse_x) > 2 or abs(mouse_y - self.prev_mouse_y) > 2:
                            pyautogui.moveTo(mouse_x, mouse_y)
                            self.prev_mouse_x, self.prev_mouse_y = mouse_x, mouse_y
                    
                    # Left click / drag
                    left_click_gesture = thumb_ext and index_ext and not middle_ext and not ring_ext and not pinky_ext
                    if left_click_gesture:
                        if self.left_gesture_start is None:
                            self.left_gesture_start = now
                        elif not self.dragging and (now - self.left_gesture_start > self.CLICK_HOLD_TIME):
                            pyautogui.mouseDown()
                            self.dragging = True
                            print("Drag Start")
                    else:
                        if self.left_gesture_start is not None:
                            hold_time = now - self.left_gesture_start
                            self.left_gesture_start = None
                            if self.dragging:
                                pyautogui.mouseUp()
                                self.dragging = False
                                print("Drag End")
                            elif hold_time <= self.CLICK_HOLD_TIME:
                                pyautogui.click()
                                print("Left Click")
                    
                    # Right click (rock sign)
                    rock_sign = index_ext and pinky_ext and not middle_ext and not ring_ext and not thumb_ext
                    if rock_sign:
                        if self.right_click_start is None:
                            self.right_click_start = now
                        elif (not self.right_click_active
                              and (now - self.right_click_start > self.RIGHT_CLICK_HOLD)
                              and (now - self.last_right_click_time > self.RIGHT_CLICK_COOLDOWN)):
                            pyautogui.click(button="right")
                            self.right_click_active = True
                            self.last_right_click_time = now
                            print("Right Click (Rock Sign)")
                    else:
                        self.right_click_start = None
                        self.right_click_active = False
                    
                    # Vertical Scroll
                    scroll_gesture = index_ext and middle_ext and ring_ext and not pinky_ext
                    if scroll_gesture and (now - self.last_scroll_time >= self.SCROLL_INTERVAL):
                        avg_y = np.mean([lms[8,1], lms[12,1], lms[16,1]])
                        finger_y_screen = int(avg_y * self.screen_height)
                        dy = finger_y_screen - self.mid_screen_y
                        if abs(dy) > self.V_DEADZONE:
                            if dy > 0:
                                pyautogui.scroll(-50)
                                print("Scroll Down")
                            else:
                                pyautogui.scroll(50)
                                print("Scroll Up")
                        self.last_scroll_time = now
            else:
                self.prev_mouse_x, self.prev_mouse_y = pyautogui.position()
            
            time.sleep(0.03)


# ==============================
# Main Emotion Recognition App
# ==============================
class EmotionRecognitionApp:
    def __init__(self, root):
        self.root = root

        # --- App state ---
        self.current_emotion = "neutral"
        self.emotion_confidence = 0.0
        self.detection_active = False
        self._proba_window = deque(maxlen=10)

        # Canonical 7 labels used by UI/actions
        self.emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']

        # Hand gesture controller
        self.gesture_controller = HandGestureController()

        # Emotion actions (same as before)
        self.emotion_actions = {
            'happy': [
                ('ğŸµ Play Upbeat Music', self.play_upbeat_music),
                ('ğŸ® Open Games Platform', self.open_games),
                ('ğŸ“º Browse YouTube', self.open_youtube),
                ('ğŸ“± Open Social Media', self.open_social_media),
                ('ğŸ“¸ Launch Camera App', self.open_camera_app),
                ('ğŸ¨ Open Paint/Creative Tools', self.open_creative_apps),
                ('ğŸ’¬ Start Video Call', self.open_video_call),
                ('ğŸ‰ Play Party Music', self.play_party_music),
                ('ğŸ“ Create Happy Journal Entry', self.open_happy_journal),
            ],
            'sad': [
                ('ğŸµ Play Comforting Music', self.play_comforting_music),
                ('ğŸ¬ Watch Comedy/Feel-Good Shows', self.watch_comedy),
                ('â˜• View Self-Care Guide', self.show_selfcare_tips),
                ('ğŸ“– Read Motivational Content', self.show_motivational_quotes),
                ('ğŸ§˜ Open Meditation App', self.open_meditation),
                ('ğŸ’¬ Connect with Friends', self.open_messaging),
                ('ğŸ“ Write in Journal', self.open_journal),
                ('ğŸŒˆ Watch Mood-Lifting Videos', self.open_mood_lifting),
                ('ğŸ§ Listen to Healing Sounds', self.play_healing_music),
                ('ğŸ†˜ View Support Resources', self.show_support_resources),
                ('ğŸŒ» Positive Affirmations', self.show_affirmations),
                ('ğŸ“ Contact Helpline Info', self.show_emergency_contacts),
            ],
            'angry': [
                ('ğŸµ Play Calming Music', self.play_calming_music),
                ('ğŸ§˜ Start Breathing Exercise', self.start_breathing_exercise),
                ('ğŸƒ Open Workout/Exercise Videos', self.open_fitness_app),
                ('âœï¸ Vent in Journal', self.open_journal),
                ('ğŸŒ¿ Listen to Nature Sounds', self.play_nature_sounds),
                ('ğŸ® Play Stress-Relief Games', self.open_stress_games),
                ('ğŸ¥Š Virtual Stress Relief', self.open_stress_relief),
                ('ğŸ“Š Anger Management Tips', self.show_anger_tips),
                ('ğŸ¯ Redirect Energy Productively', self.suggest_productive_activity),
                ('ğŸ’ª Physical Exercise Guide', self.suggest_exercise),
                ('ğŸ§Š Cool Down Technique', self.show_cooldown_tips),
                ('ğŸ“‰ Track Your Triggers', self.open_mood_tracker),
            ],
            'fear': [
                ('ğŸµ Play Comforting Music', self.play_comforting_music),
                ('ğŸ§˜ Guided Meditation', self.open_meditation),
                ('ğŸ“ Emergency Contacts', self.show_emergency_contacts),
                ('ğŸ’ª Empowerment Content', self.show_motivational_quotes),
                ('ğŸŒŸ Positive Affirmations', self.show_affirmations),
                ('ğŸ”’ Safety Resources', self.show_safety_resources),
                ('ğŸ’¬ Support Chat', self.open_support_chat),
                ('ğŸ§ Anxiety Relief Audio', self.play_anxiety_relief),
                ('ğŸŒ¬ï¸ Breathing Exercises', self.start_breathing_exercise),
                ('ğŸ“ Write Your Worries', self.open_journal),
                ('ğŸ›¡ï¸ Grounding Techniques', self.show_grounding_techniques),
                ('â˜®ï¸ Peace and Calm Guide', self.show_peace_guide),
            ],
            'surprise': [
                ('ğŸ“¸ Capture This Moment', self.open_camera_app),
                ('ğŸ“± Share on Social Media', self.open_social_media),
                ('ğŸµ Play Energetic Music', self.play_upbeat_music),
                ('ğŸ“ Document Your Thoughts', self.open_journal),
                ('ğŸ‰ Celebration Ideas', self.show_celebration_ideas),
                ('ğŸ“¹ Record Video Message', self.open_video_recorder),
                ('ğŸŠ Share Your Excitement', self.open_messaging),
                ('âš¡ Explore Exciting Content', self.open_exciting_content),
                ('ğŸ¯ Channel This Energy', self.suggest_productive_activity),
                ('ğŸŒŸ Reflect on the Moment', self.show_reflection_prompt),
            ],
            'disgust': [
                ('ğŸŒ¿ Fresh Air Reminder', self.suggest_fresh_air),
                ('ğŸµ Play Pleasant Music', self.play_relaxing_music),
                ('ğŸ§˜ Mindfulness Exercise', self.open_meditation),
                ('ğŸš¿ Self-Care Routine Guide', self.show_selfcare_tips),
                ('ğŸŒ¸ View Beautiful Nature', self.show_nature_content),
                ('ğŸ§¼ Cleansing Rituals', self.show_cleansing_tips),
                ('ğŸµ Comfort Recipes', self.show_comfort_recipes),
                ('ğŸ¨ Art Therapy', self.open_art_therapy),
                ('ğŸŒŠ Cleansing Visualization', self.show_cleansing_visualization),
                ('ğŸ’š Reset Your Space', self.show_space_reset_tips),
            ],
            'neutral': [
                ('ğŸµ Discover New Music', self.discover_music),
                ('ğŸ“š Learn Something New', self.open_learning_resources),
                ('ğŸ® Browse Casual Games', self.open_games),
                ('ğŸ“º Explore Entertainment', self.open_youtube),
                ('ğŸ’­ Start Mood Journal', self.open_journal),
                ('ğŸ¯ Open Productivity Apps', self.open_productivity),
                ('ğŸŒ Explore Your Interests', self.explore_interests),
                ('ğŸ“Š Daily Planning Tool', self.open_planner),
                ('ğŸ§© Brain Training Games', self.open_brain_games),
                ('ğŸ“– Read Articles/News', self.open_reading),
                ('ğŸ¨ Creative Projects', self.open_creative_apps),
                ('ğŸŒŸ Set New Goals', self.open_goal_setting),
            ],
        }

        # UI + model + camera
        self.setup_ui()
        self.setup_model()
        self.setup_camera()
        self.setup_responsive_layout()

        # Start maximized
        try:
            if platform.system() == "Windows":
                self.root.state('zoomed')
            else:
                self.root.attributes('-zoomed', True)
        except Exception:
            pass

    def setup_ui(self):
        self.root.title("Emotion Recognition + Gesture Control Assistant")
        self.root.configure(bg='#1a1a1a')
        self.root.minsize(1000, 700)

        style = ttk.Style()
        style.theme_use('clam')
        style.configure('Dark.TFrame', background='#1a1a1a')
        style.configure('Dark.TLabel', background='#1a1a1a', foreground='#ffffff', font=('Segoe UI', 10))
        style.configure('Title.TLabel', background='#1a1a1a', foreground='#ffffff', font=('Segoe UI', 18, 'bold'))
        style.configure('Emotion.TLabel', background='#1a1a1a', foreground='#00ff88', font=('Segoe UI', 16, 'bold'))
        style.configure('Dark.TButton', background='#333333', foreground='#ffffff', font=('Segoe UI', 9), padding=8)
        style.map('Dark.TButton', background=[('active', '#444444'), ('pressed', '#555555')])
        style.configure('Gesture.TButton', background='#2a4a7c', foreground='#ffffff', font=('Segoe UI', 9), padding=8)
        style.map('Gesture.TButton', background=[('active', '#3a5a8c'), ('pressed', '#4a6a9c')])

        # Main container
        main_container = ttk.Frame(self.root, style='Dark.TFrame')
        main_container.pack(fill='both', expand=True, padx=15, pady=15)
        main_container.grid_rowconfigure(1, weight=1)
        main_container.grid_columnconfigure(0, weight=2)
        main_container.grid_columnconfigure(1, weight=1)
        main_container.grid_columnconfigure(2, weight=2)

        # Title
        title_label = ttk.Label(main_container, text="ğŸ­ Emotion Recognition + Gesture Control Assistant", style='Title.TLabel')
        title_label.grid(row=0, column=0, columnspan=3, pady=(0, 15), sticky='ew')

        # LEFT COLUMN - Camera
        left_frame = ttk.Frame(main_container, style='Dark.TFrame')
        left_frame.grid(row=1, column=0, sticky='nsew', padx=(0, 10))
        left_frame.grid_rowconfigure(1, weight=1)
        left_frame.grid_columnconfigure(0, weight=1)

        camera_label = ttk.Label(left_frame, text="ğŸ“¹ Live Camera Feed", style='Dark.TLabel',
                                 font=('Segoe UI', 12, 'bold'))
        camera_label.grid(row=0, column=0, pady=(0, 10), sticky='w')

        self.camera_container = ttk.Frame(left_frame, style='Dark.TFrame')
        self.camera_container.grid(row=1, column=0, sticky='nsew')
        self.camera_container.grid_rowconfigure(0, weight=1)
        self.camera_container.grid_columnconfigure(0, weight=1)

        self.video_label = ttk.Label(self.camera_container, style='Dark.TLabel', anchor='center')
        self.video_label.grid(row=0, column=0, sticky='nsew')

        # Control frame with gesture control
        control_frame = ttk.Frame(left_frame, style='Dark.TFrame')
        control_frame.grid(row=2, column=0, pady=(10, 0), sticky='ew')
        control_frame.grid_columnconfigure(0, weight=1)
        control_frame.grid_columnconfigure(1, weight=1)
        control_frame.grid_columnconfigure(2, weight=1)

        self.start_btn = ttk.Button(control_frame, text="â–¶ï¸ Start Detection", style='Dark.TButton',
                                    command=self.start_detection)
        self.start_btn.grid(row=0, column=0, padx=(0, 5), sticky='ew')

        self.stop_btn = ttk.Button(control_frame, text="â¹ï¸ Stop Detection", style='Dark.TButton',
                                   command=self.stop_detection, state='disabled')
        self.stop_btn.grid(row=0, column=1, padx=5, sticky='ew')

        self.gesture_btn = ttk.Button(control_frame, text="ğŸ–ï¸ Enable Gestures", style='Gesture.TButton',
                                     command=self.toggle_gesture_control, state='disabled')
        self.gesture_btn.grid(row=0, column=2, padx=(5, 0), sticky='ew')

        # Gesture status label
        self.gesture_status_label = ttk.Label(left_frame, text="Gesture Control: OFF", 
                                             style='Dark.TLabel', font=('Segoe UI', 10, 'italic'))
        self.gesture_status_label.grid(row=3, column=0, pady=(5, 0), sticky='w')

        # MIDDLE COLUMN - Emotion Display
        middle_frame = ttk.Frame(main_container, style='Dark.TFrame')
        middle_frame.grid(row=1, column=1, sticky='nsew', padx=10)
        middle_frame.grid_rowconfigure(2, weight=1)
        middle_frame.grid_columnconfigure(0, weight=1)

        emotion_title = ttk.Label(middle_frame, text="ğŸ¯ Current Emotion", style='Dark.TLabel',
                                  font=('Segoe UI', 12, 'bold'))
        emotion_title.grid(row=0, column=0, pady=(0, 15), sticky='ew')

        emotion_display_frame = ttk.Frame(middle_frame, style='Dark.TFrame')
        emotion_display_frame.grid(row=1, column=0, pady=(0, 20), sticky='ew')
        self.emotion_icon_label = ttk.Label(emotion_display_frame, text="ğŸ˜", font=('Segoe UI', 64),
                                            style='Dark.TLabel', anchor='center')
        self.emotion_icon_label.pack()
        self.emotion_text_label = ttk.Label(emotion_display_frame, text="Neutral", style='Emotion.TLabel')
        self.emotion_text_label.pack()
        self.confidence_label = ttk.Label(emotion_display_frame, text="Confidence: 0%", style='Dark.TLabel',
                                          font=('Segoe UI', 11))
        self.confidence_label.pack(pady=(5, 0))

        history_label = ttk.Label(middle_frame, text="ğŸ“Š Recent Emotions", style='Dark.TLabel',
                                  font=('Segoe UI', 11, 'bold'))
        history_label.grid(row=2, column=0, pady=(20, 10), sticky='new')
        self.history_frame = ttk.Frame(middle_frame, style='Dark.TFrame')
        self.history_frame.grid(row=3, column=0, sticky='nsew')

        # RIGHT COLUMN - Actions
        right_frame = ttk.Frame(main_container, style='Dark.TFrame')
        right_frame.grid(row=1, column=2, sticky='nsew', padx=(10, 0))
        right_frame.grid_rowconfigure(1, weight=1)
        right_frame.grid_columnconfigure(0, weight=1)

        actions_label = ttk.Label(right_frame, text="ğŸ’¡ Suggested Actions", style='Dark.TLabel',
                                  font=('Segoe UI', 12, 'bold'))
        actions_label.grid(row=0, column=0, pady=(0, 10), sticky='w')

        self.actions_canvas = tk.Canvas(right_frame, bg='#2a2a2a', highlightthickness=0)
        actions_scrollbar = ttk.Scrollbar(right_frame, orient="vertical", command=self.actions_canvas.yview)
        self.actions_scrollable_frame = ttk.Frame(self.actions_canvas, style='Dark.TFrame')

        self.actions_scrollable_frame.bind(
            "<Configure>", lambda e: self.actions_canvas.configure(scrollregion=self.actions_canvas.bbox("all"))
        )
        self.actions_canvas.bind('<Configure>', self._on_canvas_configure)

        self.actions_canvas.create_window((0, 0), window=self.actions_scrollable_frame, anchor="nw")
        self.actions_canvas.configure(yscrollcommand=actions_scrollbar.set)
        self.actions_canvas.grid(row=1, column=0, sticky='nsew')
        actions_scrollbar.grid(row=1, column=1, sticky='ns')

        self.update_action_suggestions()

    def _on_canvas_configure(self, event):
        items = self.actions_canvas.find_withtag("all")
        if items:
            self.actions_canvas.itemconfig(items[0], width=event.width)

    def setup_responsive_layout(self):
        self.root.bind('<Configure>', self._on_window_configure)
        self._last_width = self.root.winfo_width()
        self._last_height = self.root.winfo_height()

    def _on_window_configure(self, event):
        if event.widget == self.root:
            current_width = event.width
            current_height = event.height
            if abs(current_width - self._last_width) > 10 or abs(current_height - self._last_height) > 10:
                self._last_width = current_width
                self._last_height = current_height
                self.root.update_idletasks()

    def setup_model(self):
        try:
            self.model = joblib.load(MODEL_PATH)
            self.label_encoder = joblib.load(LABELS_PATH)
            self.model_loaded = True
            print("Loaded:", MODEL_PATH, LABELS_PATH)
            print("Feature order ({}): {}".format(len(FEATURE_ORDER), FEATURE_ORDER))
        except Exception as e:
            self.model_loaded = False
            messagebox.showerror("Model Error", f"Failed to load model/labels: {e}")

    def setup_camera(self):
        try:
            self.cap = cv2.VideoCapture(0)
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.face_mesh = mp_face_mesh.FaceMesh(
                static_image_mode=False,
                refine_landmarks=False,
                max_num_faces=1,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )
            print("Camera + FaceMesh initialized")
        except Exception as e:
            print(f"Error initializing camera: {e}")
            self.cap = None
            self.face_mesh = None

    def _canonical_label(self, label: str) -> str:
        s = (label or "").strip().lower()
        mapping = {
            "anger": "angry", "angry": "angry",
            "disgust": "disgust", "disgusted": "disgust",
            "fear": "fear", "fearful": "fear",
            "happy": "happy", "happiness": "happy",
            "neutral": "neutral",
            "sad": "sad", "sadness": "sad",
            "surprise": "surprise", "surprised": "surprise",
        }
        return mapping.get(s, "neutral")

    def _actions_for(self, canonical_label: str):
        return self.emotion_actions.get(canonical_label) or self.emotion_actions["neutral"]

    def predict_emotion_from_frame(self, frame_bgr):
        if not self.model_loaded or self.face_mesh is None:
            return "neutral", 0.0

        h, w = frame_bgr.shape[:2]
        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        res = self.face_mesh.process(rgb)
        if not res.multi_face_landmarks:
            return "neutral", 0.0

        lm = res.multi_face_landmarks[0]
        landmarks = []
        for p in lm.landmark:
            x_px = int(round(p.x * w))
            y_px = int(round(p.y * h))
            z_px = p.z * w
            landmarks.append((x_px, y_px, z_px))

        feat_dict = compute_features(landmarks, w, h)
        x = np.array([feat_dict.get(name, 0.0) for name in FEATURE_ORDER], dtype=np.float32).reshape(1, -1)
        if x.shape[1] != len(FEATURE_ORDER):
            x = x[:, :len(FEATURE_ORDER)] if x.shape[1] > len(FEATURE_ORDER) else \
                np.pad(x, ((0, 0), (0, len(FEATURE_ORDER) - x.shape[1])), mode='constant', constant_values=0.0)

        try:
            proba = self.model.predict_proba(x)[0] if hasattr(self.model, "predict_proba") \
                else self._one_hot(self.model.predict(x), self.label_encoder.classes_.shape[0])
        except Exception:
            scores = getattr(self.model, "decision_function", lambda X: self.model.predict_proba(X))(x)
            e = np.exp(scores - np.max(scores))
            proba = (e / e.sum()).ravel()

        self._proba_window.append(proba)
        smoothed = np.mean(np.stack(self._proba_window, axis=0), axis=0)
        idx = int(np.argmax(smoothed))
        confidence = float(smoothed[idx])
        raw_label = self.label_encoder.inverse_transform([idx])[0]
        label = self._canonical_label(raw_label)
        return label, confidence

    @staticmethod
    def _one_hot(y_pred, n_classes):
        arr = np.zeros((1, n_classes), dtype=np.float32)
        arr[0, int(y_pred[0])] = 1.0
        return arr

    def detect_emotions(self):
        while self.detection_active:
            if self.cap is None:
                break

            ok, frame = self.cap.read()
            if not ok:
                continue
            frame = cv2.flip(frame, 1)

            emotion, confidence = self.predict_emotion_from_frame(frame)
            cv2.putText(frame, f'{emotion}: {confidence:.2f}', (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)

            self.root.after(0, self.update_emotion_display, emotion, confidence)

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            container_width = max(self.camera_container.winfo_width(), 400)
            container_height = max(self.camera_container.winfo_height(), 300)

            aspect = frame_rgb.shape[1] / frame_rgb.shape[0]
            if container_width / container_height > aspect:
                new_height = container_height
                new_width = int(container_height * aspect)
            else:
                new_width = container_width
                new_height = int(container_width / aspect)

            frame_pil = Image.fromarray(frame_rgb).resize((new_width, new_height), Image.Resampling.LANCZOS)
            frame_tk = ImageTk.PhotoImage(frame_pil)
            self.root.after(0, self.update_video_display, frame_tk)

            time.sleep(0.03)

    def update_video_display(self, frame_tk):
        self.video_label.configure(image=frame_tk)
        self.video_label.image = frame_tk

    def update_emotion_display(self, emotion, confidence):
        emotion = self._canonical_label(emotion)
        changed = (emotion != self.current_emotion)
        self.current_emotion = emotion
        self.emotion_confidence = confidence

        self.emotion_icon_label.configure(text=self.get_emotion_icon(emotion))
        self.emotion_text_label.configure(text=emotion.capitalize())
        self.confidence_label.configure(text=f"Confidence: {confidence:.1%}")

        if changed:
            self.update_action_suggestions()
        self.add_to_history(emotion, confidence)

    def add_to_history(self, emotion, confidence):
        for w in self.history_frame.winfo_children():
            w.destroy()
        history_text = f"{self.get_emotion_icon(emotion)} {emotion.capitalize()} - {confidence:.1%}"
        ttk.Label(self.history_frame, text=history_text, style='Dark.TLabel',
                  font=('Segoe UI', 10)).pack(anchor='w', pady=3)

    def update_action_suggestions(self):
        for w in self.actions_scrollable_frame.winfo_children():
            w.destroy()
        actions = self._actions_for(self.current_emotion)
        for text, func in actions:
            ttk.Button(self.actions_scrollable_frame, text=text, style='Dark.TButton',
                       command=func).pack(fill='x', pady=4, padx=6)
        self.actions_scrollable_frame.update_idletasks()
        self.actions_canvas.configure(scrollregion=self.actions_canvas.bbox("all"))
        self.actions_canvas.yview_moveto(0.0)

    def get_emotion_icon(self, emotion):
        icons = {'angry': 'ğŸ˜ ', 'disgust': 'ğŸ¤¢', 'fear': 'ğŸ˜¨', 'happy': 'ğŸ˜Š', 'neutral': 'ğŸ˜', 'sad': 'ğŸ˜¢', 'surprise': 'ğŸ˜®'}
        return icons.get(emotion, 'ğŸ˜')

    def start_detection(self):
        if not self.model_loaded:
            messagebox.showerror("Error", "Model not loaded")
            return
        if self.cap is None:
            messagebox.showerror("Error", "Camera not available")
            return
        self.detection_active = True
        self.start_btn.configure(state='disabled')
        self.stop_btn.configure(state='normal')
        self.gesture_btn.configure(state='normal')
        threading.Thread(target=self.detect_emotions, daemon=True).start()

    def stop_detection(self):
        self.detection_active = False
        self.start_btn.configure(state='normal')
        self.stop_btn.configure(state='disabled')
        self.gesture_btn.configure(state='disabled')
        
        # Stop gesture control if active
        if self.gesture_controller.running:
            self.gesture_controller.stop()
            self.gesture_btn.configure(text="ğŸ–ï¸ Enable Gestures")
            self.gesture_status_label.configure(text="Gesture Control: OFF")

    def toggle_gesture_control(self):
        if not self.gesture_controller.running:
            self.gesture_controller.start(self.cap)
            self.gesture_btn.configure(text="ğŸ–ï¸ Disable Gestures")
            self.gesture_status_label.configure(text="Gesture Control: ON (Show 5 fingers to activate mouse)")
            messagebox.showinfo("Gesture Control", 
                              "Hand Gesture Control Enabled!\n\n"
                              "â€¢ Show 5 fingers: Toggle mouse control ON/OFF\n"
                              "â€¢ Index finger: Move cursor\n"
                              "â€¢ Thumb + Index: Click (hold for drag)\n"
                              "â€¢ Index + Pinky (rock sign): Right click\n"
                              "â€¢ Index + Middle + Ring: Scroll (move hand up/down)")
        else:
            self.gesture_controller.stop()
            self.gesture_btn.configure(text="ğŸ–ï¸ Enable Gestures")
            self.gesture_status_label.configure(text="Gesture Control: OFF")

    # ========== ALL ACTION METHODS (UNCHANGED) ==========
    def play_upbeat_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=upbeat+happy+music+playlist")
        messagebox.showinfo("ğŸµ Music", "Opening upbeat music to match your mood!")
    
    def play_party_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=party+dance+music")
        messagebox.showinfo("ğŸ‰ Party Time", "Let's get the party started!")
    
    def open_creative_apps(self):
        if platform.system() == "Windows":
            try: subprocess.Popen("mspaint.exe"); messagebox.showinfo("ğŸ¨ Creative", "Opening Paint for you!")
            except: webbrowser.open("https://www.photopea.com"); messagebox.showinfo("ğŸ¨ Creative", "Opening online creative tools!")
        else:
            webbrowser.open("https://www.photopea.com"); messagebox.showinfo("ğŸ¨ Creative", "Opening creative tools for you!")
    
    def open_video_call(self):
        webbrowser.open("https://meet.google.com"); messagebox.showinfo("ğŸ’¬ Connect", "Share your happiness with friends!")
    
    def open_happy_journal(self):
        self.open_journal(); messagebox.showinfo("ğŸ“ Journal", "Document your happiness!")

    def play_comforting_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=comforting+peaceful+music")
        messagebox.showinfo("ğŸµ Comfort", "Playing music to comfort you...")
    
    def watch_comedy(self):
        webbrowser.open("https://www.youtube.com/results?search_query=funny+comedy+videos+2024")
        messagebox.showinfo("ğŸ˜„ Comedy", "Let's lift your spirits with some laughter!")
    
    def open_mood_lifting(self):
        webbrowser.open("https://www.youtube.com/results?search_query=mood+lifting+feel+good+videos")
        messagebox.showinfo("ğŸŒˆ Feel Good", "Here's something to brighten your day!")
    
    def open_messaging(self):
        webbrowser.open("https://web.whatsapp.com"); messagebox.showinfo("ğŸ’¬ Connect", "Reach out to someone!")
    
    def play_healing_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=healing+music+emotional")
        messagebox.showinfo("ğŸ§ Healing", "Let this music help heal your heart...")
    
    def show_support_resources(self):
        messagebox.showinfo("ğŸ†˜ Support","You're not alone. Support is available:\n\nâ€¢ Mental Health Hotline: 1-800-662-4357\nâ€¢ Crisis Text Line: Text HOME to 741741\nâ€¢ Suicide Prevention: 988\n")

    def play_calming_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=calming+meditation+music")
        messagebox.showinfo("ğŸµ Calm", "Soothing sounds for inner peace...")
    
    def open_fitness_app(self):
        webbrowser.open("https://www.youtube.com/results?search_query=quick+workout+anger+relief")
        messagebox.showinfo("ğŸƒ Exercise", "Channel that energy into movement!")
    
    def open_stress_games(self):
        webbrowser.open("https://www.crazygames.com/t/stress-relief"); messagebox.showinfo("ğŸ® Games", "Try these stress-relief games!")
    
    def open_stress_relief(self):
        webbrowser.open("https://www.youtube.com/results?search_query=virtual+stress+relief+activities"); messagebox.showinfo("ğŸ¥Š Relief", "Let it out in a healthy way!")
    
    def show_anger_tips(self):
        tips = ["Take 10 deep breaths slowly","Count backwards from 100","Go for a brisk walk","Write down what's bothering you","Listen to calming music","Do some intense exercise","Squeeze a stress ball","Step away from the situation"]
        messagebox.showinfo("ğŸ’¡ Anger Management", f"Try this:\n\n{np.random.choice(tips)}")
    
    def suggest_productive_activity(self):
        activities = ["Organize your workspace","Clean a room","Do a workout","Learn a new skill online","Work on a project","Plan tomorrow's tasks"]
        messagebox.showinfo("ğŸ¯ Productive", f"Channel your energy:\n\n{np.random.choice(activities)}")
    
    def show_cooldown_tips(self):
        messagebox.showinfo("ğŸ§Š Cool Down","â€¢ Splash cold water on your face\nâ€¢ Take 5 slow, deep breaths\nâ€¢ Count to 10 slowly\nâ€¢ Step outside for fresh air\nâ€¢ Drink cold water")
    
    def open_mood_tracker(self):
        self.open_journal(); messagebox.showinfo("ğŸ“‰ Track", "Document what triggered this feeling.")

    def show_safety_resources(self):
        messagebox.showinfo("ğŸ”’ Safety", "Resources:\nâ€¢ Crisis Helpline: 988\nâ€¢ Emergency: 911\nâ€¢ Crisis Text: HOME to 741741")
    
    def open_support_chat(self):
        webbrowser.open("https://www.7cups.com"); messagebox.showinfo("ğŸ’¬ Support", "Connect with trained listeners.")
    
    def play_anxiety_relief(self):
        webbrowser.open("https://www.youtube.com/results?search_query=anxiety+relief+calming+sounds"); messagebox.showinfo("ğŸ§ Calm", "Soothing sounds to ease anxiety...")
    
    def show_grounding_techniques(self):
        messagebox.showinfo("ğŸ›¡ï¸ Grounding", "5-4-3-2-1 Technique:\n5 see â€¢ 4 touch â€¢ 3 hear â€¢ 2 smell â€¢ 1 taste")
    
    def show_peace_guide(self):
        messagebox.showinfo("â˜®ï¸ Peace", "Focus on breathing. You are safe. This will pass.")

    def open_video_recorder(self):
        if platform.system() == "Windows":
            try: subprocess.Popen("start microsoft.windows.camera:", shell=True); messagebox.showinfo("ğŸ“¹ Camera", "Capture this moment!")
            except: messagebox.showinfo("ğŸ“¹ Camera", "Open your camera app to record this moment!")
        else:
            messagebox.showinfo("ğŸ“¹ Camera", "Open your camera app to capture this moment!")
    
    def open_exciting_content(self):
        webbrowser.open("https://www.youtube.com/results?search_query=exciting+amazing+moments"); messagebox.showinfo("âš¡ Exciting", "More amazing content for you!")
    
    def show_reflection_prompt(self):
        prompts = ["What surprised you most?","How does this make you feel?","Who would you like to share this with?"]
        messagebox.showinfo("ğŸŒŸ Reflect", f"Take a moment:\n\n{np.random.choice(prompts)}")

    def suggest_fresh_air(self):
        messagebox.showinfo("ğŸŒ¿ Fresh Air","Step outside for 5 deep breaths and look at something green.")
    
    def show_cleansing_tips(self):
        tips = ["Take a refreshing shower","Open windows for fresh air","Organize your space","Change into clean clothes"]
        messagebox.showinfo("ğŸ§¼ Cleansing", f"Try this:\n\n{np.random.choice(tips)}")
    
    def show_comfort_recipes(self):
        webbrowser.open("https://www.youtube.com/results?search_query=comfort+food+recipes"); messagebox.showinfo("ğŸµ Comfort", "Find something comforting to make!")
    
    def open_art_therapy(self):
        webbrowser.open("https://www.youtube.com/results?search_query=art+therapy+relaxing"); messagebox.showinfo("ğŸ¨ Art Therapy", "Express yourself through art!")
    
    def show_cleansing_visualization(self):
        messagebox.showinfo("ğŸŒŠ Visualization","Imagine a waterfall washing away the negativity.")
    
    def show_space_reset_tips(self):
        messagebox.showinfo("ğŸ’š Space Reset","Open windows, clear clutter, play uplifting music.")

    def discover_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=music+discovery+mix"); messagebox.showinfo("ğŸµ Discover", "Find new music you'll love!")
    
    def open_learning_resources(self):
        webbrowser.open("https://www.coursera.org"); messagebox.showinfo("ğŸ“š Learn", "Explore free courses.")
    
    def open_productivity(self):
        webbrowser.open("https://todoist.com"); messagebox.showinfo("ğŸ¯ Productivity", "Get organized.")
    
    def explore_interests(self):
        webbrowser.open("https://www.youtube.com/"); messagebox.showinfo("ğŸŒ Explore", "Discover something new today!")
    
    def open_planner(self):
        try:
            if platform.system() == "Windows": subprocess.Popen("notepad.exe")
            elif platform.system() == "Darwin": subprocess.Popen(["open", "-a", "TextEdit"])
            else: subprocess.Popen(["gedit"])
            messagebox.showinfo("ğŸ“Š Planning", "Plan your day ahead!")
        except: messagebox.showinfo("ğŸ“Š Planning", "Open your favorite note app to plan your day!")
    
    def open_brain_games(self):
        webbrowser.open("https://www.lumosity.com"); messagebox.showinfo("ğŸ§© Brain Games", "Challenge your mind!")
    
    def open_reading(self):
        webbrowser.open("https://medium.com"); messagebox.showinfo("ğŸ“– Reading", "Discover interesting articles.")
    
    def open_goal_setting(self):
        self.open_journal(); messagebox.showinfo("ğŸŒŸ Goals", "Write down your goals and aspirations.")
    
    def play_relaxing_music(self):
        webbrowser.open("https://www.youtube.com/results?search_query=relaxing+calm+music"); messagebox.showinfo("ğŸµ Relax", "Peaceful music to calm your mind!")
    
    def play_nature_sounds(self):
        webbrowser.open("https://www.youtube.com/results?search_query=nature+sounds+rain+forest"); messagebox.showinfo("ğŸŒ¿ Nature", "Immerse yourself in nature sounds!")
    
    def open_games(self):
        if platform.system() == "Windows":
            try: subprocess.Popen("start steam://", shell=True); messagebox.showinfo("ğŸ® Games", "Opening Steam!")
            except: webbrowser.open("https://www.crazygames.com"); messagebox.showinfo("ğŸ® Games", "Time for some fun online games!")
        else:
            webbrowser.open("https://www.crazygames.com"); messagebox.showinfo("ğŸ® Games", "Time for some fun!")
    
    def open_youtube(self):
        webbrowser.open("https://www.youtube.com"); messagebox.showinfo("ğŸ“º YouTube", "Explore videos that interest you!")
    
    def open_social_media(self):
        webbrowser.open("https://www.twitter.com"); messagebox.showinfo("ğŸ“± Social", "Connect with your network!")
    
    def open_camera_app(self):
        if platform.system() == "Windows":
            try: subprocess.Popen("start microsoft.windows.camera:", shell=True); messagebox.showinfo("ğŸ“¸ Camera", "Camera opened!")
            except: messagebox.showinfo("ğŸ“¸ Camera", "Open your camera app to capture moments!")
        elif platform.system() == "Darwin":
            messagebox.showinfo("ğŸ“¸ Camera", "Open Photo Booth to capture moments!")
        else:
            messagebox.showinfo("ğŸ“¸ Camera", "Open your camera app to capture moments!")
    
    def show_selfcare_tips(self):
        tips = ["Take a warm bath","Deep breathing 5 minutes","Go for a peaceful walk","Call a friend","Write in a journal","Gentle stretching","Make a comforting drink","Read a chapter of a book"]
        messagebox.showinfo("ğŸ’ Self-Care", f"Self-care tip:\n\n{np.random.choice(tips)}")
    
    def show_motivational_quotes(self):
        quotes = ["Every day is a new beginning!","You are stronger than you think!","This too shall pass.","Believe in yourself!","You've got this!","Progress, not perfection.","You are capable of amazing things!"]
        messagebox.showinfo("âœ¨ Motivation", np.random.choice(quotes))
    
    def open_meditation(self):
        webbrowser.open("https://www.youtube.com/results?search_query=guided+meditation+10+minutes"); messagebox.showinfo("ğŸ§˜ Meditation", "Find inner peace with guided meditation!")
    
    def start_breathing_exercise(self):
        messagebox.showinfo("ğŸŒ¬ï¸ Breathing Exercise","IN 4 â€¢ HOLD 4 â€¢ OUT 6 â€¢ HOLD 2\nRepeat 5â€“10 times.")
    
    def suggest_exercise(self):
        exercises = ["10-minute brisk walk","20 jumping jacks","5-minute yoga session","Dance to your favorite song","10 push-ups","Full-body stretch"]
        messagebox.showinfo("ğŸƒ Exercise", f"Try this:\n\n{np.random.choice(exercises)}")
    
    def open_journal(self):
        try:
            if platform.system() == "Windows": subprocess.Popen("notepad.exe")
            elif platform.system() == "Darwin": subprocess.Popen(["open", "-a", "TextEdit"])
            else: subprocess.Popen(["gedit"])
            messagebox.showinfo("âœï¸ Journal", "Express your thoughts in writing!")
        except:
            webbrowser.open("https://docs.google.com"); messagebox.showinfo("âœï¸ Journal", "Opening Google Docs for journaling!")
    
    def show_emergency_contacts(self):
        messagebox.showinfo("ğŸ†˜ Emergency Support","Help is available 24/7:\nâ€¢ 988 (US)\nâ€¢ 911 (Emergency)\nâ€¢ Text HOME to 741741")
    
    def show_affirmations(self):
        affirmations = ["I am brave and capable.","I focus on what I can control.","I am safe right now.","I am resilient.","I deserve peace and happiness."]
        messagebox.showinfo("ğŸ’« Affirmation", np.random.choice(affirmations))
    
    def show_celebration_ideas(self):
        ideas = ["Share with friends","Treat yourself","Take a photo","Happy dance","Journal the moment"]
        messagebox.showinfo("ğŸ‰ Celebrate", f"Try this:\n\n{np.random.choice(ideas)}")
    
    def show_nature_content(self):
        webbrowser.open("https://www.youtube.com/results?search_query=beautiful+nature+scenery+4k+relaxing"); messagebox.showinfo("ğŸŒ¸ Nature", "Immerse yourself in beautiful nature!")

    def __del__(self):
        if hasattr(self, 'cap') and self.cap is not None:
            self.cap.release()
        if hasattr(self, 'face_mesh') and self.face_mesh is not None:
            self.face_mesh.close()
        if hasattr(self, 'gesture_controller'):
            self.gesture_controller.stop()


def main():
    root = tk.Tk()
    app = EmotionRecognitionApp(root)

    def on_closing():
        app.detection_active = False
        app.gesture_controller.stop()
        if hasattr(app, 'cap') and app.cap is not None:
            app.cap.release()
        if hasattr(app, 'face_mesh') and app.face_mesh is not None:
            app.face_mesh.close()
        root.destroy()

    root.protocol("WM_DELETE_WINDOW", on_closing)
    root.mainloop()


if __name__ == "__main__":
    main()